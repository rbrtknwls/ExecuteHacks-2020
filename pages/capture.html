<html>
<head>
    <title>TODO</title>

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Hammersmith+One&display=swap" rel="stylesheet">

    <link rel="stylesheet" href="/css/style.css"/>

    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO"
    crossorigin="anonymous">
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://unpkg.com/react@16/umd/react.development.js" crossorigin></script>
    <script src="face-api.js"></script>
    <script src="https://unpkg.com/react-dom@16/umd/react-dom.development.js" crossorigin></script>
</head>

<style>
    .button-group, .play-area {
        border: 1px solid red;
        padding: 1em 1%;
        margin-bottom: 1em;
    }

    .button {
        padding: 0.5em;
        margin-right: 1em;
    }

    .play-area-sub {
        width: 47%;
        padding: 1em 1%;
        display: inline-block;
        text-align: center;
        color: red;
    }

    #container {
        position: relative;
    }

    #capture {
        display: none;
    }

    #snapshot {
        display: inline-block;
        width: 320px;
        height: 240px;
    }

</style>

<body>
    <div class="containera"> <!-- I dont like boostrap containers so i added the a so it wouldnt be one-->
        <button id="person1">Med</button>

        <div id="tab" class="tab row">
            <div class="image col-1">
            </div>
        <div class="health-level col-3">
            <h1>HEALTH LEVEL:</h1>
            <div id="bars"> </div>
        </div>
        <div id="emotion" class="emotion col-1">

        </div>
        <div class="text col-7">
            <h2 id="feeling-title">Lorem Ipsum</h2>
            <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque vitae elementum orci, sollicitudin pellentesque tortor. Nulla facilisi. Proin tempor, ex ac pharetra placerat, metus ante feugiat neque
            </p>
        </div>
    </div>

    <!-- The buttons to control the stream -->
    <div class="button-group">
        <button id="btn-start" type="button" class="button">Start Streaming</button>
        <button id="btn-stop" type="button" class="button">Stop Streaming</button>
        <button id="btn-capture" type="button" class="button">Capture Image</button>
    </div>

    <!-- Video Element & Canvas -->
    <div class="play-area">
        <div class="play-area-sub">
            <div class="container">

                <video id="stream" width="1" height="1"></video>
                <canvas id="streamCanvas" width="2900" height="1200"></canvas>
            </div>
        </div>

    </div>

    <input type="hidden" id="image-uri" value="">
</body>

<script>
    // The buttons to start & stop stream and to capture the image
    var btnStart = document.getElementById( "btn-start" );
    var btnStop = document.getElementById( "btn-stop" );
    var btnCapture = document.getElementById( "btn-capture" );

    // The stream & capture
    var stream = document.getElementById( "stream" );
    var capture = document.getElementById( "capture" );
    var snapshot = document.getElementById( "snapshot" );

    // The video stream
    var cameraStream = null;

    // Attach listeners
    btnStart.addEventListener( "click", startStreaming );
    btnStop.addEventListener( "click", stopStreaming );
    btnCapture.addEventListener( "click", captureSnapshot );

    // Processed stream
    var video = document.querySelector("#stream");
    var canvas = document.querySelector("#streamCanvas");
    canvas.style.display="none";
    var cctx = canvas.getContext('2d');

    // Start Streaming
    function startStreaming() {
        var mediaSupport = 'mediaDevices' in navigator;
        if( mediaSupport && null == cameraStream ) {
            navigator.mediaDevices.getUserMedia( { video: true } )
                .then( function( mediaStream ) {
                    cameraStream = mediaStream;
                    stream.srcObject = mediaStream;
                    stream.play();
                    canvas.style.display="";
                })
                .catch( function( err ) {

                    console.log( "Unable to access camera: " + err );
                });
        }
        else {
            alert( 'Your browser does not support media devices.' );
            return;
        }
    }

    // Stop Streaming
    function stopStreaming() {
        if( null != cameraStream ) {
            var track = cameraStream.getTracks()[ 0 ];
            track.stop();
            stream.load();
            cameraStream = null;
            canvas.style.display="none";
        }
    }

    function captureSnapshot() {
        if( null != cameraStream ) {
            var ctx = capture.getContext( '2d' );
            var img = new Image();
            ctx.drawImage( stream, 0, 0, capture.width, capture.height );
            img.src		= capture.toDataURL( "image/png" );
            document.getElementById("image-uri").value = img.src;
            img.width	= 180;
            img.height = 180;
            snapshot.innerHTML = '';
            snapshot.appendChild( img );
        }
    }

    // Processed data
    var _x = 50;
    var _y = 50;
    var _height = 100;
    var _width =  100;
    var _color = "red";
    var _lineWidth = "3";

    function drawProcessed(){
        cctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        cctx.beginPath();
        cctx.rect(_x,_y,_width,_height);
        cctx.lineWidth = _lineWidth;
        cctx.strokeStyle = _color;
        cctx.stroke();

        setTimeout(drawProcessed, 100);
    }
    drawProcessed();

</script>

<script src="/js/main.js"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy"
crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/paper.js/0.12.0/paper-core.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/particles.js@2.0.0/particles.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>

<script src="/socket.io/socket.io.js"></script>
        <script src="js/jquery-2.1.1.min.js"></script>
<script src="/js/client-socket.js" charset="utf-8"></script>
<script>
     $(document).ready(function(){

         async function face(){

             const MODEL_URL = '/models'

             await faceapi.loadSsdMobilenetv1Model(MODEL_URL)
             await faceapi.loadFaceLandmarkModel(MODEL_URL)
             await faceapi.loadFaceRecognitionModel(MODEL_URL)

             const img= document.getElementById('refimg')
             let fullFaceDescriptions = await faceapi.detectAllFaces(img).withFaceLandmarks().withFaceDescriptors()
             const canvas = $('#reflay').get(0)
             faceapi.matchDimensions(canvas, img)

             fullFaceDescriptions = faceapi.resizeResults(fullFaceDescriptions, img)
             faceapi.draw.drawDetections(canvas, fullFaceDescriptions)
             faceapi.draw.drawFaceLandmarks(canvas, fullFaceDescriptions)

             const labels = ['prof', 'rio', 'tokyo', 'berlin', 'nairobi']

             const labeledFaceDescriptors = await Promise.all(
                 labels.map(async label => {
                     // fetch image data from urls and convert blob to HTMLImage element
                     const imgUrl = `img/${label}.jpg`
                     const img = await faceapi.fetchImage(imgUrl)

                     // detect the face with the highest score in the image and compute it's landmarks and face descriptor
                     const fullFaceDescription = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor()

                     if (!fullFaceDescription) {
                     throw new Error(`no faces detected for ${label}`)
                     }

                     const faceDescriptors = [fullFaceDescription.descriptor]
                     return new faceapi.LabeledFaceDescriptors(label, faceDescriptors)
                 })
             );

             const maxDescriptorDistance = 0.6
             const faceMatcher = new faceapi.FaceMatcher(labeledFaceDescriptors, maxDescriptorDistance)

             const results = fullFaceDescriptions.map(fd => faceMatcher.findBestMatch(fd.descriptor))

             results.forEach((bestMatch, i) => {
                 const box = fullFaceDescriptions[i].detection.box
                 const text = bestMatch.toString()
                 const drawBox = new faceapi.draw.DrawBox(box, { label: text })
                 drawBox.draw(canvas)
             })


         }

         face()
     })
 </script>

</html>
